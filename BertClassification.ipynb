{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BertClassification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOOHyD/woItEKnjekODIK2w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VJgnqc5BJT_v"},"source":["# BERT（Keras BERT）を使用した文章分類を学習から予測まで紹介！ | cloud.config Tech Blog\n","https://tech-blog.cloud-config.jp/2020-02-06-category-classification-using-bert\n","\n","https://yoheikikuta.github.io/bert-japanese/  \n","必要データ一覧\n","\n","BERT用のファイル\n","*   model.ckpt-1400000.data-00000-of-00001\n","*   model.ckpt-1400000.meta\n","*   model.ckpt-1400000.index\n","\n","SentencePiece用のファイル\n","*   wiki-ja.vocab\n","*   wiki-ja.model"]},{"cell_type":"markdown","metadata":{"id":"ZOtYHpcwfkd5"},"source":["## ライブラリのインストール"]},{"cell_type":"code","metadata":{"id":"griQhU8udUDQ","executionInfo":{"status":"ok","timestamp":1604636095732,"user_tz":-540,"elapsed":13502,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"94111219-edfb-4506-d50a-aeb250352884","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install sentencepiece\n","!pip install keras_bert"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 6.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 6.7MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.94\n","Collecting keras_bert\n","  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.18.5)\n","Requirement already satisfied: Keras>=2.4.3 in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.4.3)\n","Collecting keras-transformer>=0.38.0\n","  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras_bert) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras_bert) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.4.3->keras_bert) (2.10.0)\n","Collecting keras-pos-embd>=0.11.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.27.0\n","  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n","Collecting keras-layer-normalization>=0.14.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.4.3->keras_bert) (1.15.0)\n","Collecting keras-self-attention==0.46.0\n","  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n","Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34145 sha256=571eda3e0b4b74a0cb71955168fd7a133abe4d7eb7209db2b1aaae75c879bab0\n","  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12942 sha256=e08a7ce95054574cbcfb1c9ec6e4f96f4eb9683c35152d2ace18d882fdd1547d\n","  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=dc5c63784985c1e234869337382d538a3d893b6f76c87859ffa26d6ed320b13d\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=0d6834e3479a5314c0b7a3c3651939cd681fc2f3cd6ddd90d2c62560aa911d55\n","  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=07b015252c6186f8e64f0ebed947e7ef3eee279ed97aebefc67792efc1092874\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5626 sha256=bc8fb1cd3eddce1824dd010fce35bdb3e0a0fb5684a5f1e1dfb05903f0507493\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=add09f13238d4ca5fea7733c95c63dfbee05a2b61ca77a649947eadfd7f3c986\n","  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=5b26c32939629902e59bcd18d8647817e4101986ffa37f57d3cc7ac59c58f953\n","  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n","Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n","Successfully installed keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZWAsSsJlq3OQ"},"source":["import pandas as pd\n","import numpy as np\n","import sentencepiece as spm\n","import csv\n","from google.colab import drive\n","from google.colab import files\n","import sys\n","from keras_bert import load_trained_model_from_checkpoint"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quk8oyrpxMZA","executionInfo":{"status":"ok","timestamp":1604636169902,"user_tz":-540,"elapsed":747,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"25016b48-39e6-4387-e73c-afbe68903ca0","colab":{"base_uri":"https://localhost:8080/"}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fri Nov  6 04:16:09 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   58C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C7Z3GmCvdsXR"},"source":["## GoogleDriveのマウント"]},{"cell_type":"code","metadata":{"id":"kstLsTPOe6yh","executionInfo":{"status":"ok","timestamp":1604636213015,"user_tz":-540,"elapsed":28416,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"265e341d-f619-4d0c-d168-e1f1e94aeb59","colab":{"base_uri":"https://localhost:8080/"}},"source":["drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tda1ZD589gaa"},"source":["data_dir = '/content/drive/My Drive/dev/bertclass/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a9m5vf_x9OvK"},"source":["## データ準備"]},{"cell_type":"code","metadata":{"id":"NQJMIDzo9Bwm","executionInfo":{"status":"ok","timestamp":1604548513046,"user_tz":-540,"elapsed":595,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"70e85b5e-8f11-482a-edd5-8d0bca1bc888","colab":{"base_uri":"https://localhost:8080/"}},"source":["# CSVとして保存\n","# Pythonでcsvファイルへの書き出し(list,numpy,pandas対応) | 超初心者向けPython入門講座\n","# https://work-life-enj.com/pyhon-write-csv/\n","\n","f = open(data_dir + 'KNBC/all.csv')\n","data = csv.reader(f)\n","\n","test_data = []\n","\n","for row in data:\n","  test_data.append(row)\n","\n","f.close()\n","\n","print(test_data[:3])\n","\n","# feature/labelを列ごとに取得\n","# features = [item[1] for item in test_data]\n","# 1個のデータをリストとして登録しないと、CSVに落とした時に、1文字1要素に分解される\n","features,labels = [],[]\n","for item in test_data:\n","    if item[1] == \"\":\n","        continue\n","    features.append([item[1]])\n","    labels.append([item[0]])\n","print(features[:4])\n","print(labels[:4])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['Gourmet', '烏丸六角のおかき屋さん'], ['Gourmet', '六角堂の前にある、蕪村庵というお店に行ってきた。'], ['Gourmet', 'おかきやせんべいの店なのだが、これがオイシイ。']]\n","[['烏丸六角のおかき屋さん'], ['六角堂の前にある、蕪村庵というお店に行ってきた。'], ['おかきやせんべいの店なのだが、これがオイシイ。'], ['のれんをくぐると小さな庭があり、その先に町屋風の店内がある。']]\n","[['Gourmet'], ['Gourmet'], ['Gourmet'], ['Gourmet']]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uh0jaH0zBxOk","executionInfo":{"status":"ok","timestamp":1604548542282,"user_tz":-540,"elapsed":1393,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"62ba42da-23d2-4b5d-e9c3-4a5a0cf8767b","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["from sklearn.model_selection import train_test_split\n","\n","# ランダムシード：0、データの並び替え：する\n","x_train, x_test, t_train, t_test = train_test_split(features, labels, train_size=0.7, random_state=0)\n","\n","def list2csv_dl(list,title,csvfile):\n","  f = open(csvfile, 'w')\n","  # 必ずダブルクオーテーションで囲むように\n","  writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n","  writer.writerow([title])\n","  writer.writerows(list)\n","  f.close()\n","  files.download(csvfile)\n","  print(list[:3])\n","\n","list2csv_dl(x_train,'feature','feature_train.csv')\n","list2csv_dl(x_test,'feature','feature_test.csv')\n","list2csv_dl(t_train,'label','label_train.csv')\n","list2csv_dl(t_test,'label','label_test.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_37f66a42-aaec-4748-af34-6ed9cd70b397\", \"feature_train.csv\", 267099)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[['・・・とうとう見てしまいましたよ。'], ['・パソコンのかわりにはなりません'], ['食べるのは大好き！！']]\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_b9c32052-cc03-4f00-9d3b-f5ed80813fd7\", \"feature_test.csv\", 115637)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[['かなりきついコースでした。'], ['それに尽きる。'], ['ほかにもお財布携帯にも対応しているし、ＣＤからお気に入りの曲を着信音に設定する等等様々な機能をもっている。']]\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_030ed922-7dbb-488d-a967-edc584d47a8a\", \"label_train.csv\", 28757)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[['Keitai'], ['Keitai'], ['Gourmet']]\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_e1d4329a-d848-4e3e-b268-37b63d7fcfba\", \"label_test.csv\", 12367)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[['Kyoto'], ['Keitai'], ['Keitai']]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nnOFpWAxdnGh"},"source":["### 最大トークン数の調査\n","\n","max_token_number: 3138\n","\n","max_position_embeddingsとmax_seq_lengthの値を使用する学習データセットの最大トークン数に\n","bert_finetuning_config_v1.json"]},{"cell_type":"code","metadata":{"id":"HHZVuFXtJL-g","executionInfo":{"status":"ok","timestamp":1604548843413,"user_tz":-540,"elapsed":1110,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"40275e71-0e0e-484a-8a5b-9d15580dd24e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# feature.csvは上記で用意したファイルのパスを指定してください\n","train_features_df = pd.read_csv(data_dir + 'trains/feature_train.csv')\n","print(train_features_df.head())\n","def _get_indice(feature):\n","    tokens = []\n","    tokens.append('[CLS]')\n","    tokens.extend(sp.encode_as_pieces(feature))\n","    tokens.append('[SEP]')\n","    number = len(tokens)\n","\n","    return number\n","\n","sp = spm.SentencePieceProcessor()\n","# ダウンロードした事前学習モデルのパスを指定してください\n","sp.Load(data_dir + 'wiki-ja.model')\n","\n","numbers = []\n","\n","for feature in train_features_df['feature']:\n","    features_number = _get_indice(feature)\n","    numbers.append(features_number)\n","\n","# 最大トークン数\n","max_token_num = max(numbers)\n","print(\"max_token_number: \" + str(max_token_num))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                                             feature\n","0                                  ・・・とうとう見てしまいましたよ。\n","1                                   ・パソコンのかわりにはなりません\n","2                                         食べるのは大好き！！\n","3                                               ・鹿苑寺\n","4  『あぁー……。まぁ買う人もいるんですけどねー……（笑）…ぁ、チョクチョクいるんですよ（笑）ホ...\n","max_token_number: 103\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pHBdCbTIfpxg"},"source":["## BERTの設定ファイル、モデルのロード\n","\n","学習回数と事前に調べていた最大トークン数、ファイルパスを自分用に書き換えてください。以下に書き換える箇所を示します。\n","\n","\n","*   config_path：設定ファイルのパス\n","*   checkpoint_path：事前学習モデルのファイルパス\n","    *   拡張子まで書かないでください\n","*   SEQ_LEN：最大トークン数\n","*   EPOCH：学習回数\n","\n","```\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in set_weights(self, weights)\n","   1824           raise ValueError(\n","   1825               'Layer weight shape %s not compatible with provided weight '\n","-> 1826               'shape %s' % (ref_shape, weight.shape))\n","   1827         weight_value_tuples.append((param, weight))\n","   1828         weight_index += 1\n","\n","ValueError: Layer weight shape (3138, 768) not compatible with provided weight shape (512, 768)\n","```"]},{"cell_type":"code","metadata":{"id":"vUPs3k1jgCGV","executionInfo":{"status":"ok","timestamp":1604636324663,"user_tz":-540,"elapsed":101452,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"8c40692e-b283-4fbf-9277-b6dc9f6cf6cb","colab":{"base_uri":"https://localhost:8080/"}},"source":["%%time\n","sys.path.append('modules')\n","\n","# BERTのロード\n","config_path = data_dir + 'bert_finetuning_config_v1.json'\n","# 拡張子まで記載しない\n","checkpoint_path = data_dir + 'model.ckpt-1400000'\n","\n","# 最大のトークン数\n","SEQ_LEN = 103\n","BATCH_SIZE = 16\n","BERT_DIM = 768\n","LR = 1e-4\n","# 学習回数\n","EPOCH = 20\n","\n","bert = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True,  trainable=True, seq_len=SEQ_LEN)\n","bert.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        [(None, 103)]        0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      [(None, 103)]        0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (TokenEmbedding [(None, 103, 768), ( 24576000    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, 103, 768)     1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, 103, 768)     0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, 103, 768)     79104       Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, 103, 768)     0           Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, 103, 768)     1536        Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 103, 768)     0           Embedding-Norm[0][0]             \n","                                                                 Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-1-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-1-MultiHeadSelfAttention-\n","                                                                 Encoder-1-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n","                                                                 Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-2-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-2-MultiHeadSelfAttention-\n","                                                                 Encoder-2-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n","                                                                 Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-3-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-3-MultiHeadSelfAttention-\n","                                                                 Encoder-3-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n","                                                                 Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-4-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-4-MultiHeadSelfAttention-\n","                                                                 Encoder-4-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n","                                                                 Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-5-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-5-MultiHeadSelfAttention-\n","                                                                 Encoder-5-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n","                                                                 Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-6-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-6-MultiHeadSelfAttention-\n","                                                                 Encoder-6-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n","                                                                 Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-7-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-7-MultiHeadSelfAttention-\n","                                                                 Encoder-7-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n","                                                                 Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-8-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-8-MultiHeadSelfAttention-\n","                                                                 Encoder-8-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n","                                                                 Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-9-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-9-MultiHeadSelfAttention-\n","                                                                 Encoder-9-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 103, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n","                                                                 Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 103, 768)     1536        Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward (FeedFor (None, 103, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Dropout  (None, 103, 768)     0           Encoder-10-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Add (Add (None, 103, 768)     0           Encoder-10-MultiHeadSelfAttention\n","                                                                 Encoder-10-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Norm (La (None, 103, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 103, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n","                                                                 Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 103, 768)     1536        Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward (FeedFor (None, 103, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Dropout  (None, 103, 768)     0           Encoder-11-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Add (Add (None, 103, 768)     0           Encoder-11-MultiHeadSelfAttention\n","                                                                 Encoder-11-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Norm (La (None, 103, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 103, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n","                                                                 Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 103, 768)     1536        Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward (FeedFor (None, 103, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Dropout  (None, 103, 768)     0           Encoder-12-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Add (Add (None, 103, 768)     0           Encoder-12-MultiHeadSelfAttention\n","                                                                 Encoder-12-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Norm (La (None, 103, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","MLM-Dense (Dense)               (None, 103, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","MLM-Norm (LayerNormalization)   (None, 103, 768)     1536        MLM-Dense[0][0]                  \n","__________________________________________________________________________________________________\n","Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","MLM-Sim (EmbeddingSimilarity)   (None, 103, 32000)   32000       MLM-Norm[0][0]                   \n","                                                                 Embedding-Token[0][1]            \n","__________________________________________________________________________________________________\n","Input-Masked (InputLayer)       [(None, 103)]        0                                            \n","__________________________________________________________________________________________________\n","NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n","__________________________________________________________________________________________________\n","MLM (Masked)                    (None, 103, 32000)   0           MLM-Sim[0][0]                    \n","                                                                 Input-Masked[0][0]               \n","__________________________________________________________________________________________________\n","NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n","==================================================================================================\n","Total params: 110,928,898\n","Trainable params: 110,928,898\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","CPU times: user 5.25 s, sys: 1.26 s, total: 6.51 s\n","Wall time: 1min 40s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M_kjrj2Ul13d"},"source":["from keras import utils\n","\n","\n","maxlen = SEQ_LEN\n"," \n","sp = spm.SentencePieceProcessor()\n","sp.Load(data_dir + 'wiki-ja.model')\n","\n","def _get_indice(feature):\n","    indices = np.zeros((maxlen), dtype = np.int32)\n","\n","    tokens = []\n","    tokens.append('[CLS]')\n","    tokens.extend(sp.encode_as_pieces(feature))\n","    tokens.append('[SEP]')\n","\n","    for t, token in enumerate(tokens):\n","        if t >= maxlen:\n","            break\n","        try:\n","            indices[t] = sp.piece_to_id(token)\n","        except:\n","            logging.warn(f'{token} is unknown.')\n","            indices[t] = sp.piece_to_id('<unk>')\n","\n","    return indices\n","\n","def _load_labeldata(train_dir, test_dir):\n","    train_features_df = pd.read_csv(f'{train_dir}/feature_train.csv')\n","    train_labels_df = pd.read_csv(f'{train_dir}/label_train.csv')\n","    test_features_df = pd.read_csv(f'{test_dir}/feature_test.csv')\n","    test_labels_df = pd.read_csv(f'{test_dir}/label_test.csv')\n","    label2index = {k: i for i, k in enumerate(train_labels_df['label'].unique())}\n","    index2label = {i: k for i, k in enumerate(train_labels_df['label'].unique())}\n","    class_count = len(label2index)\n","    # train_labels = utils.np_utils.to_categorical([label2index[label] for label in train_labels_df['label']], num_classes=class_count)\n","    train_labels = utils.to_categorical([label2index[label] for label in train_labels_df['label']], num_classes=class_count)\n","    test_label_indices = [label2index[label] for label in test_labels_df['label']]\n","    # test_labels = utils.np_utils.to_categorical(test_label_indices, num_classes=class_count)\n","    test_labels = utils.to_categorical(test_label_indices, num_classes=class_count)\n","\n","    train_features = []\n","    test_features = []\n","\n","    for feature in train_features_df['feature']:\n","        train_features.append(_get_indice(feature))\n","    train_segments = np.zeros((len(train_features), maxlen), dtype = np.float32)\n","    for feature in test_features_df['feature']:\n","        test_features.append(_get_indice(feature))\n","    test_segments = np.zeros((len(test_features), maxlen), dtype = np.float32)\n","\n","    print(f'Trainデータ数: {len(train_features_df)}, Testデータ数: {len(test_features_df)}, ラベル数: {class_count}')\n","\n","    return {\n","        'class_count': class_count,\n","        'label2index': label2index,\n","        'index2label': index2label,\n","        'train_labels': train_labels,\n","        'test_labels': test_labels,\n","        'test_label_indices': test_label_indices,\n","        'train_features': np.array(train_features),\n","        'train_segments': np.array(train_segments),\n","        'test_features': np.array(test_features),\n","        'test_segments': np.array(test_segments),\n","        'input_len': maxlen\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PF2we6fKmZuM"},"source":["## モデル作成関数"]},{"cell_type":"code","metadata":{"id":"sPqc2nM-mcra"},"source":["from keras.layers import Dense, Dropout, LSTM, Bidirectional, Flatten, GlobalMaxPooling1D\n","from keras_bert.layers import MaskedGlobalMaxPool1D\n","from keras import Input, Model\n","from keras_bert import AdamWarmup, calc_train_steps\n","\n","def _create_model(input_shape, class_count):\n","    decay_steps, warmup_steps = calc_train_steps(\n","        input_shape[0],\n","        batch_size=BATCH_SIZE,\n","        epochs=EPOCH,\n","    )\n","\n","    bert_last = bert.get_layer(name='NSP-Dense').output\n","    x1 = bert_last\n","    output_tensor = Dense(class_count, activation='softmax')(x1)\n","    # Trainableの場合は、Input Masked Layerが3番目の入力なりますが、\n","    # FineTuning時には必要無いので1, 2番目の入力だけ使用します。\n","    # Trainableでなければkeras-bertのModel.inputそのままで問題ありません。\n","    model = Model([bert.input[0], bert.input[1]], output_tensor)\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=AdamWarmup(decay_steps=decay_steps, warmup_steps=warmup_steps, lr=LR),\n","                  #optimizer='nadam',\n","                  metrics=['mae', 'mse', 'acc'])\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TimPn4sPmmYm"},"source":["## 学習データのロードとモデルの準備\n","事前準備で作成した学習用データと学習後のモデル名および出力先を指定してください。  \n","\n","*   trains_dir,tests_dir：学習用データのパス\n","*   model_filename：学習後のモデル名、出力先のパス"]},{"cell_type":"code","metadata":{"id":"LPQk1T19mieX","executionInfo":{"status":"ok","timestamp":1604639825036,"user_tz":-540,"elapsed":685,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"0b423438-1cdc-4713-e188-b11d333d2bc2","colab":{"base_uri":"https://localhost:8080/"}},"source":["%%time\n","# データロードとモデルの準備\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n","\n","trains_dir = data_dir + 'trains'\n","tests_dir = data_dir + 'tests'\n","\n","data = _load_labeldata(trains_dir, tests_dir)\n","model_filename = data_dir + 'models/ldnews_finetuning.model'\n","model = _create_model(data['train_features'].shape, data['class_count'])\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Trainデータ数: 2919, Testデータ数: 1252, ラベル数: 4\n","Model: \"functional_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        [(None, 103)]        0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      [(None, 103)]        0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (TokenEmbedding [(None, 103, 768), ( 24576000    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, 103, 768)     1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, 103, 768)     0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, 103, 768)     79104       Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, 103, 768)     0           Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, 103, 768)     1536        Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, None, 768)    2362368     Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-1-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 103, 768)     0           Embedding-Norm[0][0]             \n","                                                                 Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-1-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-1-MultiHeadSelfAttention-\n","                                                                 Encoder-1-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-1-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-1-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-2-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n","                                                                 Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-2-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-2-MultiHeadSelfAttention-\n","                                                                 Encoder-2-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-2-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-2-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-3-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n","                                                                 Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-3-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-3-MultiHeadSelfAttention-\n","                                                                 Encoder-3-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-3-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-3-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-4-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n","                                                                 Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-4-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-4-MultiHeadSelfAttention-\n","                                                                 Encoder-4-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-4-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-4-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-5-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n","                                                                 Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-5-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-5-MultiHeadSelfAttention-\n","                                                                 Encoder-5-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-5-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-5-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-6-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n","                                                                 Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-6-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-6-MultiHeadSelfAttention-\n","                                                                 Encoder-6-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-6-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-6-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-7-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n","                                                                 Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-7-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-7-MultiHeadSelfAttention-\n","                                                                 Encoder-7-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-7-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-7-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-8-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n","                                                                 Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-8-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-8-MultiHeadSelfAttention-\n","                                                                 Encoder-8-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-8-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, None, 768)    2362368     Encoder-8-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, None, 768)    0           Encoder-9-MultiHeadSelfAttention[\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 103, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n","                                                                 Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-MultiHeadSelfAttentio (None, 103, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward (FeedForw (None, 103, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Dropout ( (None, 103, 768)     0           Encoder-9-FeedForward[0][0]      \n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Add (Add) (None, 103, 768)     0           Encoder-9-MultiHeadSelfAttention-\n","                                                                 Encoder-9-FeedForward-Dropout[0][\n","__________________________________________________________________________________________________\n","Encoder-9-FeedForward-Norm (Lay (None, 103, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-9-FeedForward-Norm[0][0] \n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 103, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n","                                                                 Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-MultiHeadSelfAttenti (None, 103, 768)     1536        Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward (FeedFor (None, 103, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Dropout  (None, 103, 768)     0           Encoder-10-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Add (Add (None, 103, 768)     0           Encoder-10-MultiHeadSelfAttention\n","                                                                 Encoder-10-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-10-FeedForward-Norm (La (None, 103, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-10-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 103, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n","                                                                 Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-MultiHeadSelfAttenti (None, 103, 768)     1536        Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward (FeedFor (None, 103, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Dropout  (None, 103, 768)     0           Encoder-11-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Add (Add (None, 103, 768)     0           Encoder-11-MultiHeadSelfAttention\n","                                                                 Encoder-11-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-11-FeedForward-Norm (La (None, 103, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, None, 768)    2362368     Encoder-11-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, None, 768)    0           Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 103, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n","                                                                 Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-MultiHeadSelfAttenti (None, 103, 768)     1536        Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward (FeedFor (None, 103, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Dropout  (None, 103, 768)     0           Encoder-12-FeedForward[0][0]     \n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Add (Add (None, 103, 768)     0           Encoder-12-MultiHeadSelfAttention\n","                                                                 Encoder-12-FeedForward-Dropout[0]\n","__________________________________________________________________________________________________\n","Encoder-12-FeedForward-Norm (La (None, 103, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n","__________________________________________________________________________________________________\n","Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n","__________________________________________________________________________________________________\n","NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 4)            3076        NSP-Dense[0][0]                  \n","==================================================================================================\n","Total params: 110,306,308\n","Trainable params: 110,306,308\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","CPU times: user 220 ms, sys: 10.6 ms, total: 230 ms\n","Wall time: 237 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E0v5jxXbXPAI"},"source":["## 計算途中のモデルの読み込み"]},{"cell_type":"code","metadata":{"id":"8Qt3aKgvXOlj","executionInfo":{"status":"error","timestamp":1604612907809,"user_tz":-540,"elapsed":1375,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"eb1ee2c3-cd37-4f2c-8e15-bfde8c08c164","colab":{"base_uri":"https://localhost:8080/","height":498}},"source":["model.load_weights(model_filename)\n","# loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n","# print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-dd8dcd7083e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to open file (file read failed: time = Thu Nov  5 21:48:26 2020\n, filename = '/content/drive/My Drive/dev/bertclass/models/ldnews_finetuning.model', file descriptor = 62, errno = 21, error message = 'Is a directory', buf = 0x7fffe6f5c120, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)"]}]},{"cell_type":"markdown","metadata":{"id":"8aIktJ8cqE7r"},"source":["## 学習の実行"]},{"cell_type":"code","metadata":{"id":"bjyRNAGyqH7o","executionInfo":{"status":"error","timestamp":1604639872305,"user_tz":-540,"elapsed":22258,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"503ade7f-7d34-470d-8c3c-08539ca1e315","colab":{"base_uri":"https://localhost:8080/","height":464}},"source":["%%time\n","history = model.fit([data['train_features'], data['train_segments']],\n","          data['train_labels'],\n","          epochs = EPOCH-17,\n","          batch_size = BATCH_SIZE,\n","          validation_data=([data['test_features'], data['test_segments']], data['test_labels']),\n","          shuffle=False,\n","          verbose = 1,\n","          callbacks = [\n","              ModelCheckpoint(monitor='val_acc', mode='max', filepath=model_filename, save_best_only=True)\n","          ])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-068bbdb0ca35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history = model.fit([data['train_features'], data['train_segments']],\\n          data['train_labels'],\\n          epochs = EPOCH-17,\\n          batch_size = BATCH_SIZE,\\n          validation_data=([data['test_features'], data['test_segments']], data['test_labels']),\\n          shuffle=False,\\n          verbose = 1,\\n          callbacks = [\\n              ModelCheckpoint(monitor='val_acc', mode='max', filepath=model_filename, save_best_only=True)\\n          ])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    814\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m         raise ValueError(\"Creating variables on a non-first call to a function\"\n\u001b[0m\u001b[1;32m    817\u001b[0m                          \" decorated with tf.function.\")\n\u001b[1;32m    818\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."]}]},{"cell_type":"code","metadata":{"id":"NHJ4GNCFqOqR"},"source":["# モデルの保存と復元  |  TensorFlow Core\n","# https://www.tensorflow.org/tutorials/keras/save_and_load?hl=ja\n","\n","'''\n","model_path  = './'\n","\n","model_flist = os.listdir(model_path)\n","model_flist = glob.glob(model_path + '*.pkl');\n","\n","// Modelのload\n","models = {}\n","for model_file in model_flist:\n","    model_name = model_file[:-4]\n","    models[model_name] = pickle.load(open(model_path + model_file, 'rb'))\n","\n","// Modelのsave\n","for model_name in models.keys():\n","    pickle.dump(models[model_name], open(model_path + model_name + '.pkl', 'wb'))\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LZLboeTIySNO"},"source":["TPU：1EPOCHあたり50～60分\n","GPI(T4)：1EPOCHあたり3分弱！\n"]},{"cell_type":"markdown","metadata":{"id":"7fs-HdZjX6uI"},"source":["## モデルの評価"]},{"cell_type":"code","metadata":{"id":"Rkvab0YrcFJO"},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","from keras.models import load_model\n","from keras_bert import get_custom_objects"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Wi_pqyXX-y-","executionInfo":{"status":"ok","timestamp":1604638543200,"user_tz":-540,"elapsed":35919,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"ea193106-ee63-4dd9-f143-8e0a9f148f32","colab":{"base_uri":"https://localhost:8080/","height":300}},"source":["%%time\n","model = load_model(model_filename, custom_objects=get_custom_objects())\n","\n","predicted_test_labels = model.predict([data['test_features'], data['test_segments']]).argmax(axis=1)\n","numeric_test_labels = np.array(data['test_labels']).argmax(axis=1)\n","\n","report = classification_report(\n","        numeric_test_labels, predicted_test_labels, target_names=['Gourmet', 'Keitai', 'Kyoto', 'Sports'], output_dict=True)\n","\n","display(pd.DataFrame(report).T)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Gourmet</th>\n","      <td>0.815934</td>\n","      <td>0.787798</td>\n","      <td>0.801619</td>\n","      <td>377.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Keitai</th>\n","      <td>0.767442</td>\n","      <td>0.717391</td>\n","      <td>0.741573</td>\n","      <td>276.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Kyoto</th>\n","      <td>0.787942</td>\n","      <td>0.865297</td>\n","      <td>0.824810</td>\n","      <td>438.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Sports</th>\n","      <td>0.798658</td>\n","      <td>0.739130</td>\n","      <td>0.767742</td>\n","      <td>161.000000</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.793131</td>\n","      <td>0.793131</td>\n","      <td>0.793131</td>\n","      <td>0.793131</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.792494</td>\n","      <td>0.777404</td>\n","      <td>0.783936</td>\n","      <td>1252.000000</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.793230</td>\n","      <td>0.793131</td>\n","      <td>0.792139</td>\n","      <td>1252.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              precision    recall  f1-score      support\n","Gourmet        0.815934  0.787798  0.801619   377.000000\n","Keitai         0.767442  0.717391  0.741573   276.000000\n","Kyoto          0.787942  0.865297  0.824810   438.000000\n","Sports         0.798658  0.739130  0.767742   161.000000\n","accuracy       0.793131  0.793131  0.793131     0.793131\n","macro avg      0.792494  0.777404  0.783936  1252.000000\n","weighted avg   0.793230  0.793131  0.792139  1252.000000"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["CPU times: user 19.9 s, sys: 3.39 s, total: 23.3 s\n","Wall time: 34.7 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LNd1Lj-xziEu"},"source":["9回回した後の結果\n","\n","data |precision|recall|f1-score|support\n","--- | --- | --- | --- | ---\n","Gourmet|0.832869|0.793103|0.812500|377.000000\n","Keitai|0.663580|0.778986|0.716667|276.000000\n","Kyoto|0.801418|0.773973|0.787456|438.000000\n","Sports|0.767123|0.695652|0.729642|161.000000\n","accuracy|0.770767|0.770767|0.770767|0.770767\n","macro avg|0.766248|0.760428|0.761566|1252.000000\n","weighted avg|0.776093|0.770767|0.771957|1252.000000"]},{"cell_type":"markdown","metadata":{"id":"K0pMgadocUui"},"source":["### モデルの学習再開"]},{"cell_type":"code","metadata":{"id":"UxBRhEGh1X_e","executionInfo":{"status":"ok","timestamp":1604639955326,"user_tz":-540,"elapsed":22365,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"928da5e5-5d14-4e53-e3ff-eb76c45e9635","colab":{"base_uri":"https://localhost:8080/"}},"source":["%%time\n","model = load_model(model_filename, custom_objects=get_custom_objects())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 15.5 s, sys: 3.06 s, total: 18.5 s\n","Wall time: 21.5 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xSx-u1Q6cPKt","executionInfo":{"status":"ok","timestamp":1604641300266,"user_tz":-540,"elapsed":1328648,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"6df9e4d4-4fde-4adf-9285-e6095daee500","colab":{"base_uri":"https://localhost:8080/"}},"source":["history = model.fit([data['train_features'], data['train_segments']],\n","          data['train_labels'],\n","          epochs = EPOCH-10,\n","          batch_size = BATCH_SIZE,\n","          validation_data=([data['test_features'], data['test_segments']], data['test_labels']),\n","          shuffle=False,\n","          verbose = 1,\n","          callbacks = [\n","              ModelCheckpoint(monitor='val_acc', mode='max', filepath=model_filename, save_best_only=True)\n","          ])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","183/183 [==============================] - ETA: 0s - loss: 0.0234 - mean_absolute_error: 0.0035 - mean_squared_error: 0.0025 - acc: 0.9935INFO:tensorflow:Assets written to: /content/drive/My Drive/dev/bertclass/models/ldnews_finetuning.model/assets\n","183/183 [==============================] - 159s 867ms/step - loss: 0.0234 - mean_absolute_error: 0.0035 - mean_squared_error: 0.0025 - acc: 0.9935 - val_loss: 1.4834 - val_mean_absolute_error: 0.1152 - val_mean_squared_error: 0.1010 - val_acc: 0.7756\n","Epoch 2/10\n","183/183 [==============================] - 131s 718ms/step - loss: 0.0605 - mean_absolute_error: 0.0114 - mean_squared_error: 0.0066 - acc: 0.9832 - val_loss: 1.4211 - val_mean_absolute_error: 0.1191 - val_mean_squared_error: 0.1052 - val_acc: 0.7652\n","Epoch 3/10\n","183/183 [==============================] - 125s 684ms/step - loss: 0.0843 - mean_absolute_error: 0.0164 - mean_squared_error: 0.0096 - acc: 0.9767 - val_loss: 1.1512 - val_mean_absolute_error: 0.1339 - val_mean_squared_error: 0.1078 - val_acc: 0.7428\n","Epoch 4/10\n","183/183 [==============================] - 125s 681ms/step - loss: 0.0653 - mean_absolute_error: 0.0128 - mean_squared_error: 0.0071 - acc: 0.9822 - val_loss: 1.3176 - val_mean_absolute_error: 0.1388 - val_mean_squared_error: 0.1140 - val_acc: 0.7340\n","Epoch 5/10\n","183/183 [==============================] - 125s 683ms/step - loss: 0.0436 - mean_absolute_error: 0.0075 - mean_squared_error: 0.0039 - acc: 0.9911 - val_loss: 1.2314 - val_mean_absolute_error: 0.1222 - val_mean_squared_error: 0.1008 - val_acc: 0.7596\n","Epoch 6/10\n","183/183 [==============================] - 125s 681ms/step - loss: 0.0190 - mean_absolute_error: 0.0041 - mean_squared_error: 0.0021 - acc: 0.9949 - val_loss: 1.2838 - val_mean_absolute_error: 0.1151 - val_mean_squared_error: 0.0996 - val_acc: 0.7716\n","Epoch 7/10\n","183/183 [==============================] - 125s 681ms/step - loss: 0.0185 - mean_absolute_error: 0.0040 - mean_squared_error: 0.0023 - acc: 0.9938 - val_loss: 1.4330 - val_mean_absolute_error: 0.1166 - val_mean_squared_error: 0.1030 - val_acc: 0.7708\n","Epoch 8/10\n","183/183 [==============================] - 125s 681ms/step - loss: 0.0180 - mean_absolute_error: 0.0040 - mean_squared_error: 0.0022 - acc: 0.9945 - val_loss: 1.4009 - val_mean_absolute_error: 0.1206 - val_mean_squared_error: 0.1044 - val_acc: 0.7612\n","Epoch 9/10\n","183/183 [==============================] - 125s 682ms/step - loss: 0.0082 - mean_absolute_error: 0.0016 - mean_squared_error: 0.0010 - acc: 0.9973 - val_loss: 1.3914 - val_mean_absolute_error: 0.1148 - val_mean_squared_error: 0.1001 - val_acc: 0.7756\n","Epoch 10/10\n","183/183 [==============================] - 125s 682ms/step - loss: 0.0048 - mean_absolute_error: 0.0012 - mean_squared_error: 7.5176e-04 - acc: 0.9979 - val_loss: 1.4355 - val_mean_absolute_error: 0.1141 - val_mean_squared_error: 0.1003 - val_acc: 0.7732\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4xh9dQ-BdWmW"},"source":["## 予測"]},{"cell_type":"markdown","metadata":{"id":"2kvEA-pmfe8K"},"source":["### 文字列から予測(出力は数字)"]},{"cell_type":"code","metadata":{"id":"ALSz9HpEdZO-","executionInfo":{"status":"error","timestamp":1604641461855,"user_tz":-540,"elapsed":21692,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"2cbd004c-4d07-4e96-b4f9-51e278b62c49","colab":{"base_uri":"https://localhost:8080/","height":430}},"source":["import sys\n","import pandas as pd\n","import sentencepiece as spm\n","import logging\n","import numpy as np\n","\n","from keras import utils\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","from keras_bert import load_trained_model_from_checkpoint\n","from keras_bert import get_custom_objects\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","\n","sys.path.append('modules')\n","\n","# SentencePieceProccerモデルの読込\n","spp = spm.SentencePieceProcessor()\n","spp.Load(data_dir + 'wiki-ja.model')\n","# BERTの学習したモデルの読込\n","model_filename = data_dir + 'models/ldnews_finetuning.model'\n","model = load_model(model_filename, custom_objects=get_custom_objects())\n","\n","SEQ_LEN = 103\n","maxlen = SEQ_LEN\n","\n","def _get_indice(feature):\n","    indices = np.zeros((maxlen), dtype=np.int32)\n","\n","    tokens = []\n","    tokens.append('[CLS]')\n","    tokens.extend(spp.encode_as_pieces(feature))\n","    tokens.append('[SEP]')\n","\n","    for t, token in enumerate(tokens):\n","        if t >= maxlen:\n","            break\n","        try:\n","            indices[t] = spp.piece_to_id(token)\n","        except:\n","            logging.warn('unknown')\n","            indices[t] = spp.piece_to_id('<unk>')\n","    return indices\n","\n","feature = \"昨日は携帯電話を買いに行った。\"\n","\n","test_features = []\n","test_features.append(_get_indice(feature))\n","test_segments = np.zeros(\n","    (len(test_features), maxlen), dtype=np.float32)\n","\n","predicted_test_labels = model.predict(\n","    [test_features, test_segments]).argmax(axis=1)\n","\n","print(predicted_test_labels[0])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-7b00bdfed502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m predicted_test_labels = model.predict(\n\u001b[0;32m---> 53\u001b[0;31m     [test_features, test_segments]).argmax(axis=1)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_test_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 103, 1\nPlease provide data which shares the same first dimension."]}]},{"cell_type":"markdown","metadata":{"id":"cAkU0xtpeM_P"},"source":["### ラベル番号をラベル名に変換するように"]},{"cell_type":"code","metadata":{"id":"vBQloOWPfBiy","executionInfo":{"status":"error","timestamp":1604641563199,"user_tz":-540,"elapsed":23958,"user":{"displayName":"A Ryo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjdWTBC8XkDzzokoOXhunbjwkTm3l4DM0mL0QlY=s64","userId":"00705155911893008194"}},"outputId":"dc063267-30d0-4446-9ed9-502dd5da8533","colab":{"base_uri":"https://localhost:8080/","height":430}},"source":["import sys\n","import pandas as pd\n","import sentencepiece as spm\n","import logging\n","import numpy as np\n","\n","from keras import utils\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","from keras_bert import load_trained_model_from_checkpoint\n","from keras_bert import get_custom_objects\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","\n","sys.path.append('modules')\n","\n","# SentencePieceProccerモデルの読込\n","spp = spm.SentencePieceProcessor()\n","spp.Load(data_dir + 'wiki-ja.model')\n","# BERTの学習したモデルの読込\n","model_filename = data_dir + 'models/ldnews_finetuning.model'\n","model = load_model(model_filename, custom_objects=get_custom_objects())\n","\n","SEQ_LEN = 103\n","maxlen = SEQ_LEN\n","\n","def _get_indice(feature):\n","    indices = np.zeros((maxlen), dtype=np.int32)\n","\n","    tokens = []\n","    tokens.append('[CLS]')\n","    tokens.extend(spp.encode_as_pieces(feature))\n","    tokens.append('[SEP]')\n","\n","    for t, token in enumerate(tokens):\n","        if t >= maxlen:\n","            break\n","        try:\n","            indices[t] = spp.piece_to_id(token)\n","        except:\n","            logging.warn('unknown')\n","            indices[t] = spp.piece_to_id('<unk>')\n","    return indices\n","\n","feature = \"昨日は携帯電話を買いに行った。\"\n","\n","test_features = []\n","test_features.append(_get_indice(feature))\n","test_segments = np.zeros(\n","    (len(test_features), maxlen), dtype=np.float32)\n","\n","predicted_test_labels = model.predict(\n","    [test_features, test_segments]).argmax(axis=1)\n","\n","label_data = pd.read_csv(data_dir + 'label_id/id_category.csv')\n","label = label_data.query(f'id == {predicted_test_labels[0]}')\n","label = label.iloc[0]\n","label_name = label['label']\n","print(label_name)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-4240233a4ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m predicted_test_labels = model.predict(\n\u001b[0;32m---> 53\u001b[0;31m     [test_features, test_segments]).argmax(axis=1)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mlabel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'label_id/id_category.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 103, 1\nPlease provide data which shares the same first dimension."]}]}]}